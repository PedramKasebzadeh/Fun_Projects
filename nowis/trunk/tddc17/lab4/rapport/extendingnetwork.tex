\section{Extending a network}

  \subsection{Question 1}
If the radio doesn't work : $P(survives | \lnot rdaio) = 0.98116$. The probability is still high because the probability of meltdown is low and because if the radio doesn't that not necessarily means that the battery is dead.

  \subsection{Question 2}
\textbf{We know :}

$P(bicycle\_works) = 0.9$

$P(survives | \lnot moves \land meltdown \land bicycle\_works) = 0.6$

$P(survives | moves \land meltdown \land bicycle\_works) = 0.9$

\textbf{So :}

$P(survives) = P(bicycle\_works) \* P(survives | bicycle\_works) + P(\lnot bicycle\_works) \* P(survives | \lnot bicycle\_works)$

\textbf{But :}

$P(survives | \lnot bicycle\_works = 0$

\textbf{And :}

$P(survives | bicycle\_works) = P(meltdown) \* P(survives | bicycle\_works \land meltdown) + P(\lnot meltdown) \* P(survives | bicycle\_world \land \lnot meltdown)
$

\textbf{But :}

$P(survives | bicycle\_world \land \lnot meltdown) = 1$

\textbf{And :}

$P(survives | bicycle\_works \land  meltdown) =  P(\lnot moves) \* P(survives | \lnot moves \land meltdown \land bicycle\_works) + P(moves) \* P(survives | moves \land meltdown \land bicycle\_works)$

\textbf{So :}

$P(survives) = P(bicycle\_works) \* (P(meltdown) \* (P(\lnot moves) \* P(survives | \lnot moves \land meltdown \land bicycle\_works) + P(moves) \* P(survives | moves \land meltdown \land bicycle\_works)) + P(\lnot meltdown))$ 

$\Leftrightarrow P(survives) = 0.9 \* (0.03 \* (0.6\*P(\lnot moves) + 0.9\*P(moves)) + 0.97)$

\textbf{If we suppose that } $P(moves) = 0.95$ \textbf{then :}

$P(survives) = 0.889605$

  \subsection{Question 3}

The complexity of exact inference in Bayesian networks, using variable elimination is exponential. We know that for exact inference in Bayesian networks ($X$ query variable, $E$ evidence variable, $Y$ unobserved variable) :

$P(X | e) = \alpha \* P(X, e) = \alpha\*\sum_{y} P(X, e, y)$

So if there is n unobserved variable :

$P(X | e) = \alpha \* \sum_{Y \in \{Y_1, Y_2, ..., Y_n\}} \sum_{y \in Y} P(X, e, y)$

So, the complexity of exact inference is the multiplication of the number of event of each unobserved. So for boolean stochastic variable : $O(2^n)$

